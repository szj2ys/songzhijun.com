---
title: Bert详解
tags:
  - Bert
keywords: 'Bert,预训练模型'
comments: true
date: 2022-01-24 20:50:06
updated: 2022-01-24 20:50:06
categories:
description:
top_img:
cover:
---


## Bert含义

双向Transformer编码表达，其中双向指的是attention矩阵中，每个字都包含前后所有字的信息。



## Bert的训练数据生成和解读
用于训练的文本材料是以行排列的句子。

首先读取一行句子，以：“工时填写。”为例，该句子会被认为是一个document和一个chunk，认定只有一个句子后，会随机从其他行的句子中挑一个出来，与该句组合成如下的结构：

```shell
[‘[CLS]’, ‘工’, ‘时’, ‘填’, ‘写’, ‘[SEP]’, ‘平’, ‘安’, ‘好’, ‘医’, ‘生’, ‘非, ‘常’, ‘优’, ‘秀’, ‘[SEP]’]
```


当然，在组合数据的过程中，会随机有如下的调整：

在mask的个数范围之内，此处举例有3个mask，其中有80%的概率某字会变成’[MASK]’，有10%的概率不会变化，有10%的概率会随机用另一个字代替它，接下来可能会变化成如下的内容：
```shell
[‘[CLS]’, ‘工’, ‘时’, ‘[MASK]’, ‘写’, ‘[SEP]’, ‘平’, ‘安’, ‘好’, ‘特’, ‘生’, ‘非, ‘常’, ‘优’, ‘秀’, ‘[SEP]’]。
```
同时我们也会得到相应的mask信息：

- segment_ids：这是一个list，用于区分句子之间的覆盖的范围，对应上述内容，其值为[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]；

- is_random_next：这是一个重点，它表示两句话之间是否有上下文关系，注意，这里的random，这表示该变量如果是True，则两句没有上下文关系，这是一个随机生成的句子对。当每个document中只有一个句子时一定会随机找一个对子与之配对，如果是两个有关的句子，则有50%的概率随机找一个句子与前一个句子配对；

- masked_lm_positions：这是一个list，表示本句中出现掩码的位置，其值为[3, 6, 9]；

- masked_lm_labels：这是一个list，是与position对应的字，其值为[‘填’, ‘平’, ‘医’]；

上述所有信息会封装在一个instance对象中。



## Bert语言模型
### Masked Language Model

一般语言模型建模的方式是从左到右或者从右到左，这样的损失函数都很直观，即预测下一个词的概率。

而Bert这种双向的网络，使得下一个词这个概念消失了，没有了目标，如何做训练呢？

答案就是完形填空，在输入中，把一些词语遮挡住，遮挡的方法就是用[Mask]这个特殊词语代替。而在预测的时候，就预测这些被遮挡住的词语。其中遮挡词语占所有词语的15%，且是每次随机Mask。

但这有一个问题：在预训练中会[Mask]这个词语，但是在下游任务中，是没有这个词语的，这会导致预训练和下游任务的不匹配。

> 
>不匹配的意思我理解就是在预训练阶段任务中，模型会学到句子中有被遮挡的词语，模型要去学习它，而在下游任务中没有，但是模型会按照预训练的习惯去做，会导致任务的不匹配。



解决的办法就是不让模型意识到有这个任务的存在，具体做法就是在所有Mask的词语中，有80%的词语继续用[Mask]特殊词语，有10%用其他词语随机替换，有10%的概率保持不变。这样，模型就不知道当前句子中有没[Mask]的词语了。



### Next Sentence Prediction
在很多下游任务中，需要判断两个句子之间的关系，比如QA问题，需要判断一个句子是不是另一个句子的答案，比如NLI(Natural Language Inference)问题，直接就是两个句子之间的三种关系判断。

因此，为了能更好的捕捉句子之间的关系，在预训练的时候，就做了一个句子级别的损失函数，这个损失函数的目的很简单，就是判断第二个句子是不是第一个句子的下一句。训练时，会随机选择生成训练语料，50%的时下一句，50%的不是。




## REFERENCES

- [Bert的训练数据生成和解读](https://zhuanlan.zhihu.com/p/157806409)

- [原生Bert的训练和使用总结](https://blog.csdn.net/BmwGaara/article/details/107557205?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5.pc_relevant_aa&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5.pc_relevant_aa&utm_relevant_index=8)


