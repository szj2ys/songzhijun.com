---
title: KNN和KMeans详解
tags:
  - KNN
  - KMeans
keywords: 'KNN、KMeans'
comments: true
date: 2022-03-08 18:05:28
updated: 2022-03-08 18:05:28
categories:
description:
top_img:
cover: https://img1.baidu.com/it/u=3722120826,4092546436&fm=253
---

## 概念
KNN（K-Nearest Neighbor），如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。

Kmeans做了几个假设，让任务更简单一点：

（1） 具体事物之间是有区别的，“区别”的大小可以用某种指标来度量。

（2） 距离较小的事物，在某些方面上比较相似，我们可以把他们归为一类。

## 原理

### KNN原理
KNN算法最简单粗暴的就是将预测点与所有点距离进行计算，然后保存并排序，选出前面K个值看看哪些类别比较多，则预测的点属于哪类。

### KMeans原理
K-Means算法的特点是类别的个数是人为给定的，如果让机器自己去找类别的个数，通过一次次重复这样的选择质心-计算距离后分类-再次选择新质心的流程，直到我们分组之后所有的数据都不会再变化了，也就得到了最终的聚合结果。

#### KMeans的缺陷
- 聚类中心的个数K 需要事先给定，但在实际中这个 K 值的选定是非常难以估计的，很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适
- KMeans需要人为地确定初始聚类中心，不同的初始聚类中心可能导致完全不同的聚类结果。（可以使用KMeans++算法来解决）

### K-Means ++ 算法

## 过程
### KNN过程
对未知类别属性的数据集中的每个点依次执行以下操作:
(1) 计算已知类别数据集中的点与当前点之间的距离;
(2) 按照距离递增次序排序;
(3) 选取与当前点距离最小的k个点;
(4) 确定前k个点所在类别的出现频率;
(5) 返回前k个点出现频率最高的类别作为当前点的预测分类。


### KMeans过程
（1）随机选取k个质心（k值取决于你想聚成几类）
（2）计算样本到质心的距离，距离质心距离近的归为一类，分为k类
（3）求出分类后的每类的新质心
（4）再次计算计算样本到新质心的距离，距离质心距离近的归为一类
（5）判断新旧聚类是否相同，如果相同就代表已经聚类成功，如果没有就循环2-4步骤直到相同


## 实例

## 异同
### 相同点
- 都包含这样的过程，给定一个点，在数据集中找离它最近的点。即二者都用到了NN(Nears Neighbor)算法，一般用KD树来实现NN。

### 不同点
- KNN属于监督学习，类别是已知的，通过对已知分类的数据进行训练和学习，找到这些不同类的特征，再对未分类的数据进行分类。

- KMeans属于非监督学习，事先不知道数据会分为几类，通过聚类分析将数据聚合成几个群体。聚类不需要对数据进行训练和学习。
- K的含义：
    - KNN：来了一个样本x，要给它分类，即求出它的y，就从数据集中，在x附近找离它最近的K个数据点，这K个数据点，类别c占的个数最多，就把x的label设为c
    - KMeans：K是人工固定好的数字，假设数据集合可以分为K个簇，由于是依靠人工定好，需要一点先验知识




## REFERENCES
- [最通俗的话解释KNN，KMeans算法](https://zhuanlan.zhihu.com/p/122195108)
- [kmeans聚类算法及其python实现](https://zhuanlan.zhihu.com/p/76631018)
- [全面解析Kmeans聚类(Python)](https://zhuanlan.zhihu.com/p/449438521)
- [10种Python聚类算法完整操作示例](https://zhuanlan.zhihu.com/p/126661239)






